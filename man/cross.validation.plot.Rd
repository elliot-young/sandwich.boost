% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cross.validation.plot.R
\name{cross.validation.plot}
\alias{cross.validation.plot}
\title{Cross Validation of the sandwich loss for selection of number of boosting iterations}
\usage{
cross.validation.plot(
  l_formula,
  l_learner,
  m_formula,
  m_learner,
  s_formula,
  s_learner,
  proxyCCF = "equicorr",
  data,
  K = 5L,
  k.cv = 10L,
  lambda_s = 1,
  lambda_theta = 0.1,
  m_stop = 200,
  init_CCF = NULL
)
}
\arguments{
\item{l_formula}{a two-sided formula object describing the regression model for \eqn{E[Y|X=x]}.}

\item{l_learner}{a string specifying the regression method to fit the regression of \eqn{Y} on \eqn{X} as given by \code{l_formula}.}

\item{m_formula}{a two-sided formula object describing the regression model for \eqn{E[D|X=x]}.}

\item{m_learner}{a string specifying the regression method to fit the regression of \eqn{D} on \eqn{X} as given by \code{m_formula}.}

\item{s_formula}{a two-sided formula object describing the regression model for a single boosting iteration for \eqn{s}-function sandwich boosting.}

\item{s_learner}{a string specifying the regression method to fit the a single boosting iteration for \eqn{s}-function sandwich boosting as given by \code{l_formula}.}

\item{proxyCCF}{a string specifying which working correlation parametrisation to use. Must take the form "\code{equicorr}", "\code{autoreg}" or "\code{nested}".}

\item{data}{a data frame containing the variables for the grouped PLR model. Note that group ID must be given by the column \code{id}.}

\item{K}{the number of folds used for cross-fitting. Default is 5.}

\item{k.cv}{number of folds used for cross-validation to determine . Default is 10.}

\item{lambda_s}{fixed step size \eqn{\lambda_s} that is sued for \eqn{s}-function steps in sandwich boosting when \code{variable_steps=FALSE}. Default is 1}

\item{lambda_theta}{step size for \eqn{\theta}-gradient descent. Default is 0.1.}

\item{m_stop}{maximum number of sandwich boosting iterations. The number of boosting iterations would therefore in practice be the minimum of value calculated by CV and \code{m_stop}. Default is 100}

\item{init_CCF}{initalisation of weight class used for \eqn{(s,\theta)}-boosting. Default is \eqn{s=1} and \eqn{\theta=0} (\code{init_CCF = NULL}). Alternatives include "\code{mem_init}" to initialise at an (intercept only) mixed effects model.}
}
\value{
Plots the CV curve for the inputted \code{(lambda_s,m_stop)} pair, alongside a list containing:
  \describe{
    \item{\code{cv.critical.vals}}{A vector containing the CV criterion (sandwich loss) evaluated at each \code{m_stop} value.}
    \item{\code{cv.m_stop}}{The m_stop that minimises the CV criterion (sandwich loss) over the inputted range.}
  }
}
\description{
Cross Validation of the sandwich loss for selection of number of boosting iterations
}
